{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import librosa as lr\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    lstm_1_res = np.argmax(lstm_1_model.predict(features))\n",
    "    # print('LSTM-1:', lstm_1_res)\n",
    "    \n",
    "    result += [lstm_1_res]\n",
    "    \n",
    "    # strong classes:\n",
    "    if lstm_1_res == 0:\n",
    "        \n",
    "        lstm_2a_res = np.argmax(lstm_2a_model.predict(features))\n",
    "        # print('LSTM-2a:', lstm_2a_res)\n",
    "        \n",
    "        result += [lstm_2a_res]\n",
    "        \n",
    "        # substrong-1:\n",
    "        if lstm_2a_res == 0:\n",
    "            \n",
    "            lstm_3a_res = np.argmax(lstm_3a_model.predict(features))\n",
    "            # print('LSTM-3a:', lstm_3a_res)\n",
    "            \n",
    "            result += [lstm_3a_res]\n",
    "            \n",
    "        # substrong-2:\n",
    "        else:\n",
    "            \n",
    "            lstm_3b_res = np.argmax(lstm_3b_model.predict(features))\n",
    "            # print('LSTM-3b:', lstm_3b_res)\n",
    "            \n",
    "            result += [lstm_3b_res]\n",
    "            \n",
    "    # mild classes:\n",
    "    else:\n",
    "        \n",
    "        lstm_2b_res = np.argmax(lstm_2b_model.predict(features))\n",
    "        # print('LSTM-2b:', lstm_2b_res)\n",
    "        \n",
    "        result += [lstm_2b_res]\n",
    "        \n",
    "        \n",
    "        # submild-1:\n",
    "        if lstm_2b_res == 0:\n",
    "            \n",
    "            lstm_3c_res = np.argmax(lstm_3c_model.predict(features))\n",
    "            # print('LSTM-3c:', lstm_3c_res)\n",
    "            \n",
    "            result += [lstm_3c_res]\n",
    "            \n",
    "        # submild-2:\n",
    "        else:\n",
    "            \n",
    "            lstm_3d_res = np.argmax(lstm_3d_model.predict(features))\n",
    "            # print('LSTM-3d:', lstm_3d_res)\n",
    "            \n",
    "            result += [lstm_3d_res]\n",
    "            \n",
    "    return lookup(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy on GTZAN Validation and Test Set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = np.load('/content/drive/MyDrive/audio-genre-classification-main/dataset/prepared/processed.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top-1 Accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_confusion_mat = np.zeros(shape=(10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ground_truth_labels = []\n",
    "\n",
    "for i in range(0, 5000, 5):\n",
    "    \n",
    "    if (i % 500) >= 5 * 90:\n",
    "        predicted = []\n",
    "        for j in range(0, 5):\n",
    "            if ((i+j) % 500) >= 5 * 90:\n",
    "                predicted += [predict(processed[i+j]['features'].reshape(1, 256, 40))]\n",
    "        \n",
    "        original = processed[i]['ground_truth']\n",
    "        \n",
    "        top_1 = Counter(predicted).most_common(n=1)\n",
    "        \n",
    "        if original == top_1[0][0]:\n",
    "            top_1_confusion_mat[genres[original]][genres[original]] += 1\n",
    "        else:\n",
    "            top_1_confusion_mat[genres[original]][genres[top_1[0][0]]] += 1\n",
    "        \n",
    "        ground_truth_labels += [original]\n",
    "        \n",
    "        print('=========================================')\n",
    "        print('Original: {}'.format(original))\n",
    "        print('Predicted: {}'.format(top_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_1_frame = pd.DataFrame(\n",
    "    data=top_1_confusion_mat,\n",
    "    index=list(genres.keys()),\n",
    "    columns=list(genres.keys())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(top_1_frame, annot=True, annot_kws={\"size\": 10})\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_1_accuracy = 100 * (np.sum(np.diag(top_1_confusion_mat)) / np.sum(top_1_confusion_mat))\n",
    "print('Top-1 Accuracy: {} %'.format(top_1_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top-2 Accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "top_2_confusion_mat = np.zeros(shape=(10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(0, 5000, 5):\n",
    "    \n",
    "    if (i % 500) >= 5 * 90:\n",
    "        predicted = []\n",
    "        for j in range(0, 5):\n",
    "            if ((i+j) % 500) >= 5 * 90:\n",
    "                predicted += [predict(processed[i+j]['features'].reshape(1, 256, 40))]\n",
    "        \n",
    "        original = processed[i]['ground_truth']\n",
    "        \n",
    "        top_2 = Counter(predicted).most_common(n=2)\n",
    "        \n",
    "        if original in [top_2[i][0] for i in range(len(top_2))]:\n",
    "            top_2_confusion_mat[genres[original]][genres[original]] += 1\n",
    "        else:\n",
    "            for i in range(len(top_2)):\n",
    "                top_2_confusion_mat[genres[original]][genres[top_2[i][0]]] += (1 / len(top_2))\n",
    "        \n",
    "        # print('=========================================')\n",
    "        # print('Original: {}'.format(original))\n",
    "        # print('Predicted: {}'.format(top_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_2_frame = pd.DataFrame(\n",
    "    data=top_2_confusion_mat,\n",
    "    index=list(genres.keys()),\n",
    "    columns=list(genres.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(top_2_frame, annot=True, annot_kws={\"size\": 10})\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_2_accuracy = 100 * (np.sum(np.diag(top_2_confusion_mat)) / np.sum(top_2_confusion_mat))\n",
    "print('Top-2 Accuracy: {} %'.format(top_2_accuracy))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d14b9ef065a62ebefff3d4e52466e399ec66c79f9b10fc53b5af93856d3c7f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
